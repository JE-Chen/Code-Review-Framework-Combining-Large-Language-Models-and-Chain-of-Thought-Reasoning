# ä¸€å€‹ã€ŒåŠŸèƒ½æ­£å¸¸ã€çš„ API Client ç¨‹å¼ï¼ˆrequests ç‰ˆ v2ï¼‰
# ä½† HTTP / Header / Cache / Stream / API è¨­è¨ˆå…¨é¢ç¿»è»Š ğŸ¤®

import requests
import time
import hashlib


# âŒ Mutable Default Argumentï¼šheaders ç•¶é è¨­åƒæ•¸ï¼Œç¶“å…¸åœ°é›·
def fetch_resource(url, headers={}, use_cache=True, allow_redirect=True):
    # âŒ Function Attribute ç•¶å¿«å–ï¼ˆHidden State in Function Objectï¼‰
    if not hasattr(fetch_resource, "cache"):
        fetch_resource.cache = {}

    # âŒ Cache Key è¨­è¨ˆéŒ¯èª¤ï¼šåªç”¨ URLï¼Œå¿½ç•¥ headers / query
    cache_key = url

    if use_cache and cache_key in fetch_resource.cache:
        # âŒ å›å‚³èˆŠ Response ç‰©ä»¶ï¼ˆStale Object Reuseï¼‰
        return fetch_resource.cache[cache_key]

    # âŒ åœ¨ function å…§å·å·ä¿®æ”¹å‚³å…¥åƒæ•¸ï¼ˆSide-effect on Argumentsï¼‰
    headers["User-Agent"] = "BadClient/1.0"

    # âŒ allow_redirects ç•¶åƒæ•¸å‚³ä¾†å‚³å»ï¼ˆLeaky Abstractionï¼‰
    r = requests.get(
        url,
        headers=headers,
        allow_redirects=allow_redirect
    )

    # âŒ Cache HTTP Response Object æœ¬èº«ï¼ˆUnsafe Object Cachingï¼‰
    if use_cache:
        fetch_resource.cache[cache_key] = r

    return r


# âŒ Shadowing Built-in Nameï¼ˆå‘½åæˆ hashï¼‰
def hash(text):
    # âŒ è‡ªå·±é‡é€ è¼ªå­ï¼ˆReinventing the Wheelï¼‰
    h = hashlib.md5()
    h.update(text.encode("utf-8"))
    return h.hexdigest()


# âŒ Confusing APIï¼šåƒæ•¸åèˆ‡å¯¦éš›ç”¨é€”ä¸ç¬¦
def download_file(url, path, preview=False, verbose=False):
    # âŒ stream=True ä½†æ²’æœ‰æ­£ç¢ºé—œé–‰ responseï¼ˆResource Leakï¼‰
    resp = requests.get(url, stream=True)

    # âŒ Verbose flag æ±¡æŸ“æ ¸å¿ƒæµç¨‹
    if verbose:
        print("Status:", resp.status_code)
        print("Headers:", resp.headers)

    content = b""

    # âŒ Magic Chunk Size
    for chunk in resp.iter_content(chunk_size=1234):
        # âŒ å‡è£æ”¯æ´ previewï¼Œå…¶å¯¦é‚„æ˜¯å…¨æŠ“
        if preview and len(content) > 3000:
            break
        content += chunk

    # âŒ ä¸æª¢æŸ¥ Content-Type å°±ç›´æ¥å­˜æª”
    with open(path, "wb") as f:
        f.write(content)

    return path


# âŒ Overloaded Functionï¼šåˆæ‰“ APIã€åˆ parse headerã€åˆç®— checksumã€åˆ sleep
def fetch_and_verify(url, delay=0.0):
    r = fetch_resource(url)

    # âŒ Logging Sensitive Headersï¼ˆè³‡å®‰è‡­å‘³ï¼‰
    print("Request headers:", r.request.headers)

    # âŒ ç›´æ¥ä¿¡ä»» encoding
    text = r.text

    # âŒ ç”¨è‡ªè£½ hash ä¾†ç•¶é©—è­‰æ©Ÿåˆ¶ï¼ˆWeak Home-grown Securityï¼‰
    checksum = hash(text)

    # âŒ Artificial Delayï¼šæ¯«ç„¡ç†ç”± sleep
    if delay > 0:
        time.sleep(delay)

    return {
        "url": url,
        "length": len(text),
        "checksum": checksum
    }


# âŒ Header State Machine Smellï¼šç”¨ dict ç•¶æµç¨‹æ§åˆ¶
def batch_fetch(urls, mode="normal"):
    results = []

    headers = {}

    # âŒ mode ç”¨å­—ä¸²æ§åˆ¶å¤šç¨®é‚è¼¯ï¼ˆStringly Typed Control Flowï¼‰
    if mode == "mobile":
        headers["User-Agent"] = "iPhone"
    elif mode == "bot":
        headers["User-Agent"] = "GoogleBot"
    else:
        headers["User-Agent"] = "Desktop"

    for u in urls:
        # âŒ æ¯æ¬¡éƒ½å…±ç”¨åŒä¸€ä»½ headersï¼ˆCross-request Contaminationï¼‰
        r = fetch_resource(u, headers=headers, use_cache=True)

        # âŒ Redirect Policy æ··åœ¨å•†æ¥­é‚è¼¯ä¸­
        if r.history:
            print("Redirected:", u, "->", r.url)

        # âŒ Tight Coupling to Header Format
        server = r.headers.get("Server", "unknown")

        results.append({
            "url": u,
            "status": r.status_code,
            "server": server,
            "size": len(r.content)
        })

    return results


# âŒ Polling API åæ¨¡å¼ï¼šå›ºå®šé–“éš”ä¸€ç›´æ‰“
def wait_until_ready(url, max_try=5):
    tries = 0

    while tries < max_try:
        r = fetch_resource(url, use_cache=False)

        # âŒ Magic Status Code Rule
        if r.status_code == 200:
            return True

        # âŒ Fixed Sleep Without Backoff
        time.sleep(1)
        tries += 1

    return False


# âŒ Output-only Functionï¼šå®Œå…¨ç„¡å›å‚³å€¼
def print_summary(results):
    print("=== FETCH SUMMARY ===")

    for r in results:
        # âŒ Inconsistent Field Order / Format
        line = (
            r["url"]
            + " | "
            + str(r["status"])
            + " | "
            + r["server"]
            + " | "
            + str(r["size"])
        )
        print(line)

    # âŒ æ˜æ˜å¯ä»¥å›å‚³è³‡æ–™å»é¸æ“‡åªå°
    return None


# ä¸»æµç¨‹
def main():
    urls = [
        "https://jsonplaceholder.typicode.com/posts/1",
        "https://jsonplaceholder.typicode.com/posts/2",
        "https://jsonplaceholder.typicode.com/users/1",
    ]

    # âŒ Temporal Couplingï¼šä¸€å®šè¦å…ˆ wait æ‰ batch
    ok = wait_until_ready(urls[0])

    if not ok:
        print("Service not ready, but continue anyway...")

    results = batch_fetch(urls, mode="bot")

    print_summary(results)

    # âŒ åŒä¸€ URL é‡è¤‡æ‰“ï¼Œä½† cache è¦å‰‡éŒ¯èª¤å¯èƒ½å›èˆŠè³‡æ–™
    info = fetch_and_verify(urls[0], delay=0.2)

    print("Verify result:", info)
